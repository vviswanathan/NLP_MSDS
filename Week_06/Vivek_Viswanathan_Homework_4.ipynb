{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this exercise, we will \n",
    "- Run a POS tagger in Python\n",
    "    - On a sentence longer than 10 words\n",
    "    - On a shorter sentence shorter than 10 words\n",
    "    - Explain why the tagger may have been less than perfect with this this sentence. \n",
    "- Run a different POS tagger in Python to tag the above 2 sentences\n",
    "    - Check if it provides different output\n",
    "    - Explain any difference in the outputs\n",
    "- Take a random sentence from a NEWS article\n",
    "    - Using Penn tag set, manually POS tag the sentence yourself\n",
    "    - Run the same sentence through both taggers that is implemented in the previous questions and check if the results were different.\n",
    "    - Explain the differences between the 2 taggers and the manual tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation Steps\n",
    "\n",
    "- Import the necessary packages\n",
    "- Select random lines from 5th grade Text rather than a made up sentence. \n",
    "    - Sentence 1 is greater than 10 words\n",
    "    - Sentence 2 is lesser than 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import nltk, re, pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_grade5_text = \"http://www.gutenberg.org/cache/epub/15040/pg15040.txt\"\n",
    "grade5_text_url_open = request.urlopen(url_grade5_text)\n",
    "text_grade5_raw = grade5_text_url_open.read().decode('utf-8-sig')\n",
    "text_grade5_raw_start = text_grade5_raw.find(\"McGuffey\\'s Fifth Reader\")\n",
    "text_grade5_raw_end = text_grade5_raw.rfind(\"End of the Project Gutenberg EBook of McGuffey\\'s Fifth Eclectic Reader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE GOOD READER.',\n",
       " '1.',\n",
       " 'It is told of Frederick the Great, King of Prussia, that, as he was\\r\\nseated one day in his private room, a written petition was brought to him\\r\\nwith the request that it should be immediately read.',\n",
       " 'The King had just\\r\\nreturned from hunting, and the glare of the sun, or some other cause, had\\r\\nso dazzled his eyes that he found it difficult to make out a single word\\r\\nof the writing.',\n",
       " '2.',\n",
       " 'His private secretary happened to be absent; and the soldier who\\r\\nbrought the petition could not read.',\n",
       " 'There was a page, or favorite boy\\r\\nservant, waiting in the hall, and upon him the King called.',\n",
       " 'The page was a\\r\\nson of one of the noblemen of the court, but proved to be a very poor\\r\\nreader.',\n",
       " '3.',\n",
       " 'In the first place, he did not articulate distinctly.',\n",
       " 'He huddled his\\r\\nwords together in the utterance, as if they were syllables of one long\\r\\nword, which he must get through with as speedily as possible.',\n",
       " 'His\\r\\npronunciation was bad, and he did not modulate his voice so as to bring\\r\\nout the meaning of what he read.',\n",
       " 'Every sentence was uttered with a dismal\\r\\nmonotony of voice, as if it did not differ in any respect from that which\\r\\npreceded it.',\n",
       " '4.',\n",
       " '\"Stop!\"',\n",
       " 'said the King, impatiently.',\n",
       " '\"Is it an auctioneer\\'s list of\\r\\ngoods to be sold that you are hurrying over?',\n",
       " 'Send your companion to me.\"',\n",
       " 'Another page who stood at the door now entered, and to him the King gave\\r\\nthe petition.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sub = text_grade5_raw[text_grade5_raw_start:text_grade5_raw_end]\n",
    "text_sent_tokenize = nltk.sent_tokenize(text_sub)\n",
    "text_sent_tokenize[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_1 = \"Is it an auctioneer's list of goods to be sold that you are hurrying over?\"\n",
    "sent_1_word_tokenize = word_tokenize(sent_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_2 = \"Send your companion to me.\"\n",
    "sent_2_word_tokenize = word_tokenize(sent_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. POS tagging using Python (Unigram Tagger)\n",
    "\n",
    "Unigram uses only single word for determining POS tag. The other variations to the N-gram taggers are Bigram and Trigram taggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = treebank.tagged_sents()[:10000]\n",
    "tagger = UnigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('an', 'DT'),\n",
       " ('auctioneer', None),\n",
       " (\"'s\", 'POS'),\n",
       " ('list', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('goods', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('sold', 'VBN'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('hurrying', None),\n",
       " ('over', 'IN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(sent_1_word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a. Interpretation\n",
    "\n",
    "The words auctioneer, hurrying were assigned a tag of None because they were not among the frist 10000 words that were used to train the tagger. However, the other words have been tagged appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Send', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('companion', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('me', 'PRP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(sent_2_word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b. Interpretation\n",
    "\n",
    "All the words were assigned a tag as they were all among the frist 10000 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. POS tagging using Python (nltk.pos_tag Tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('an', 'DT'),\n",
       " ('auctioneer', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('list', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('goods', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('sold', 'VBN'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('hurrying', 'VBG'),\n",
       " ('over', 'IN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(sent_1_word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Send', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('companion', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('me', 'PRP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(sent_2_word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Compare the outputs\n",
    "\n",
    "The nltk pos_tag package has tagged all the words in both the sentences.  \n",
    "\n",
    "#### 2b. Explaining the differences\n",
    "\n",
    "nltk.pos_tag is a pre-trained PerceptronTagger model whereas the Unigram tagger contains no pre-trained model. We have trained the Unigram tagger with the first 10000 words in treebank.tagged_sents(). It is very likely that some of the words in our sentence is not part of the 10000 words used in training the Unigram tagger and hence gets tagged as 'None'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. POS Tag on this weeks news article\n",
    "\n",
    "We take a random sentence more than 10 words from cnn.com. The sentence used for tagging would be \n",
    "- Anyone, including WH aides, could be fired depending on coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a. Manual Tagging using Penn Treebank\n",
    "\n",
    "The first method involved using the tagging the POS manually using the Penn Treebank tags https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "The manual POS tags are listed below.\n",
    "\n",
    "| Word | Tag | Description |\n",
    "| --- | --- | --- |\n",
    "| Anyone | NN | Noun, singular or mass |\n",
    "| , | , | , |\n",
    "| including | VBG | Verb, gerund or present participle |\n",
    "| WH | NNP | Proper noun, singular |\n",
    "| aides | NNS | Noun, plural |\n",
    "| , | , | , |\n",
    "| could | MD | Modal |\n",
    "| be | VB | Verb, base form |\n",
    "| fired | VBN | Verb, past participle |\n",
    "| depending | VBG | Verb, gerund or present participle |\n",
    "| on | IN | Preposition or subordinating conjunction |\n",
    "| coverage | NN | Noun, singular or mass |\n",
    "| .\t| . | . |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_news = \"Anyone, including WH aides, could be fired depending on coverage.\"\n",
    "sent_news_word_tokenize = word_tokenize(sent_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anyone', None),\n",
       " (',', ','),\n",
       " ('including', 'VBG'),\n",
       " ('WH', None),\n",
       " ('aides', 'NNS'),\n",
       " (',', ','),\n",
       " ('could', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('fired', 'VBD'),\n",
       " ('depending', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('coverage', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(sent_news_word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anyone', 'NN'),\n",
       " (',', ','),\n",
       " ('including', 'VBG'),\n",
       " ('WH', 'NNP'),\n",
       " ('aides', 'NNS'),\n",
       " (',', ','),\n",
       " ('could', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('fired', 'VBN'),\n",
       " ('depending', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('coverage', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(sent_news_word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. Compare the outputs\n",
    "\n",
    "The nltk.pos_tag produced the same result as the Penn Treebank. \n",
    "\n",
    "#### 3c. Explain differences\n",
    "Similar the first question, some of the words were not tagged using the Unigram tagger. This can be attributed to the word now showing up in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this homework, we started by using Unigram and nltk.pos_tag taggers in Python to tag a simple and a complex sentence. We compared the output between the 2 taggers and identified untagged words. The words weren't tagged because they weren't part of the training set of the Unigram tagger.\n",
    "\n",
    "We then took a random sentence from this week's news articles and tagged them manually. We compared them with the output of the 2 taggers we used in question 1 and 2 and explained differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
