{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Run one of the part-of-speech (POS) taggers available in Python. \n",
    "### a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "### b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: I am going to use the UnigramTagger to tag a longer and a shorter sentence. Before doing that I would like to train the UnigramTagger with nltk treebank corpus and then check with an existing sentence within the treebank corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = treebank.tagged_sents()[:3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = UnigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9601868352020543"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.evaluate(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent1 = treebank.sents()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neither',\n",
       " 'Lorillard',\n",
       " 'nor',\n",
       " 'the',\n",
       " 'researchers',\n",
       " 'who',\n",
       " '*T*-3',\n",
       " 'studied',\n",
       " 'the',\n",
       " 'workers',\n",
       " 'were',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'any',\n",
       " 'research',\n",
       " 'on',\n",
       " 'smokers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Kent',\n",
       " 'cigarettes',\n",
       " '.']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither -> DT\n",
      "Lorillard -> NNP\n",
      "nor -> CC\n",
      "the -> DT\n",
      "researchers -> NNS\n",
      "who -> WP\n",
      "*T*-3 -> -NONE-\n",
      "studied -> VBN\n",
      "the -> DT\n",
      "workers -> NNS\n",
      "were -> VBD\n",
      "aware -> JJ\n",
      "of -> IN\n",
      "any -> DT\n",
      "research -> NN\n",
      "on -> IN\n",
      "smokers -> NNS\n",
      "of -> IN\n",
      "the -> DT\n",
      "Kent -> NNP\n",
      "cigarettes -> NNS\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "for word, tag in tagger.tag(train_sent1):\n",
    "...     print(word, '->', tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result verified with default pos tagger in nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neither', 'DT'),\n",
       " ('Lorillard', 'NNP'),\n",
       " ('nor', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('researchers', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('*T*-3', 'VBP'),\n",
       " ('studied', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('workers', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('aware', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('research', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('smokers', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Kent', 'NNP'),\n",
       " ('cigarettes', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(train_sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on the result except for couple of tokens rest have been tagged correctly by UnigramTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now checking the UnigramTagger with a longer sentence (10 or more words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "test_sent1 = word_tokenize('Data Mining is one of the branches of machine learning and can be done using programming languages.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data -> NNP\n",
      "Mining -> NNP\n",
      "is -> VBZ\n",
      "one -> CD\n",
      "of -> IN\n",
      "the -> DT\n",
      "branches -> NNS\n",
      "of -> IN\n",
      "machine -> NN\n",
      "learning -> NN\n",
      "and -> CC\n",
      "can -> MD\n",
      "be -> VB\n",
      "done -> VBN\n",
      "using -> VBG\n",
      "programming -> NN\n",
      "languages -> NNS\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "for word, tag in tagger.tag(test_sent1):\n",
    "...     print(word, '->', tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Data', 'NNP'),\n",
       " ('Mining', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('branches', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('done', 'VBN'),\n",
       " ('using', 'VBG'),\n",
       " ('programming', 'NN'),\n",
       " ('languages', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(test_sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We get 100% accuracy for the longer sentence. Now over to a shorter sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent2 = word_tokenize('Running the errand while you run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running -> None\n",
      "the -> DT\n",
      "errand -> None\n",
      "while -> IN\n",
      "you -> PRP\n",
      "run -> VB\n"
     ]
    }
   ],
   "source": [
    "for word, tag in tagger.tag(test_sent2):\n",
    "...     print(word, '->', tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Running', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('errand', 'NN'),\n",
       " ('while', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('run', 'VBP')]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(test_sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         (Pierre, NNP)\n",
       "1         (Vinken, NNP)\n",
       "2                (,, ,)\n",
       "3              (61, CD)\n",
       "4          (years, NNS)\n",
       "              ...      \n",
       "100671    (quarter, NN)\n",
       "100672         (of, IN)\n",
       "100673       (next, JJ)\n",
       "100674       (year, NN)\n",
       "100675           (., .)\n",
       "Length: 100676, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tst_wrds = pd.Series(test_words)\n",
    "tst_wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, POS]\n",
       "Index: []"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = pd.DataFrame(test_words, columns = ['Name','POS'])\n",
    "tst[tst['Name'].str.contains(\"errand\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
